<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Ziyang Wu's Homepage</title>
    
    <link href="res/css/bootstrap.min.css" rel="stylesheet">

    <style>
      .fulljustify {
      text-align:justify;
      }
      .fulljustify:after {
        content: "";
        display: inline-block;
        width: 100%;  
      }
      #tagline {
        height: 80px;
        overflow: hidden;
        line-height: 80px; /* vert-center */
      }
      .hover {
      position: relative;
      display: inline-block;
      border-bottom: 1px dotted black;
      /*max-width: 230px;*/
      /*top: 50px;
      left: 50px;*/
      }

      .tooltip {
      /* hide and position tooltip */
      top: 5px;
      left: 193px; 
      background-color: yellow;
      color: black;
      border-radius: 5px;
      white-space: nowrap;
      opacity: 0;
      position: absolute;
   /*   -webkit-transition: opacity 0.5s;
      -moz-transition: opacity 0.5s;
      -ms-transition: opacity 0.5s;
      -o-transition: opacity 0.5s;*/
      /*transition: opacity 0.5s;*/
      }

      .hover:hover .tooltip {
      /* display tooltip on hover */
      opacity: 1;
      }
      
      body{
      margin: 50px auto;
      /*margin-left: 150px;*/
      /*margin-right: 150px;*/
      width: auto;
      max-width: 830px;
      font-family: Palatino;
      }
      blockquote {
      border-left: 5px solid #3607F2;
      }
    </style>
    <!-- Bootstrap -->
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <div class="container">
  <body>
     
    <h3> <div class="hover"> Ziyang
    <div class="tooltip"> People also call him Robin. 
    </div>
    </div> Wu </h3>
    <p> Email: zywu at berkeley dot edu/ zw287 at cornell dot edu (old)</br>
    <a href="https://scholar.google.com/citations?user=9RAHYd0AAAAJ&hl=en" target="_blank"> Google Scholar </a>  
    <hr>
    <h4> <b> Bio </b> <font size="3"></font></h4>
    <p>  I am a third-year Ph.D. student advised by <a href="https://people.eecs.berkeley.edu/~yima/"> Prof. Yi Ma</a> at UC Berkeley. 
      I obtained my MS degree at Cornell University advised by <a href="http://home.bharathh.info/"> Prof. Bharath Hariharan</a> and <a href="https://people.orie.cornell.edu/mru8/"> Prof. Madeleine Udell</a>.
      I graduated summa cum laude and received my BS degrees from Cornell University in Computer Science and in Operations Research. 
      I also spent one year working as a researcher advised by <a href="https://www.microsoft.com/en-us/research/people/hshum/"> Prof. Harry Shum</a> at International Digital Economy Academy (<a href="https://www.idea.edu.cn/">IDEA</a>) in Shenzhen, China. 
      My primary research interests lie in machine learning and computer vision.
	    <!-- publications come here -->

    <hr>
    <h4><b> Publications </b>  <font size="3"></font> </h4>
	  <p> <font size="3"> (* indicates equal contribution) </p>
    <!-- --> 
<h5> <b> Preprints </b> <font size="3"></font></h5>
  <p>
    <font size="3"> <b>Token Statistics Transformer: Linear-Time Attention via Variational Rate Reduction</b>  </font></br>
    <font size="3"> <b> Ziyang Wu </b>, Tianjiao Ding, Druv Pai, Jingyuan Zhang, Weida Wang, Yaodong Yu, Yi Ma, Benjamin Haeffele </br>
     [link(soon)] 
  </font>
  </p>

    <h5> <b> Conferences & Journals </b> <font size="3"></font></h5>

    <p>
      <font size="3"> <b> When Do We Not Need Larger Vision Models? </b> </font></br>
      <font size="3"> Baifeng Shi, <b> Ziyang Wu </b>, Maolin Mao, Xin Wang, Trevor Darrell </br>
        European Conference on Computer Vision (ECCV), 2024 </br>
      <a href="https://arxiv.org/abs/2403.13043v1" target="_blank"> [arxiv] </a> 
    </font>
    </p>

    <p>
      <font size="3"> <b>LLoCO: Learning Long Contexts Offline</b> </font></br>
      <font size="3"> Sijun Tan, Xiuyu Li, Shishir Patil, <b> Ziyang Wu </b>, Tianjun Zhang, Kurt Keutzer, Joseph E. Gonzalez, Raluca Ada Popa </br>
        Empirical Methods in Natural Language Processing (EMNLP), 2024 </br>
      <a href="https://arxiv.org/abs/2404.07979" target="_blank"> [arxiv] </a> 
    </font>
    </p>

    <p>
      <font size="3"> <b>Masked Completion via Structured Diffusion with White-Box Transformers</b>  </font></br>
      <font size="3"> Druv Pai,  <b> Ziyang Wu </b>, Tianzhe Chu, Sam Buchanan, Yaodong Yu, Yi Ma </br>
        International Conference on Learning Representations (ICLR), 2024 </br>
      <a href="https://openreview.net/forum?id=PvyOYleymy" target="_blank"> [link] </a> 
    </font>
    </p>

    <p>
      <font size="3"> <b>Emergence of Segmentation with Minimalistic White-Box Transformers</b> </font></br>
      <font size="3"> Yaodong Yu, Tianzhe Chu, Shengbang Tong, <b> Ziyang Wu </b>, Druv Pai, Sam Buchanan, Yi Ma </br>
        Conference on Parsimony and Learning (CPAL), 2024 </br>
      <a href="https://arxiv.org/abs/2308.16271" target="_blank"> [arxiv] </a> 
    </font>
    </p>

    <p>
      <font size="3"> <b>White-Box Transformers via Sparse Rate Reduction</b> </font></br>
      <font size="3"> Yaodong Yu, Sam Buchanan, Druv Pai, Tianzhe Chu,  <b> Ziyang Wu </b>, Shengbang Tong, Benjamin D Haeffele, Yi Ma </br>
        Conference on Neural Information Processing Systems (NeurIPS), 2023 </br>
      <a href="https://arxiv.org/abs/2306.01129" target="_blank"> [arxiv] </a> 
    </font>
    </p>

    <p>
      <font size="3"> <b>Incremental Learning of Structured Memory via Closed-Loop Transcription </b> </font></br>
      <font size="3"> Shengbang Tong, Xili Dai, <b> Ziyang Wu </b>, Mingyang Li, Brent Yi,  Yi Ma </br>
        International Conference on Learning Representations (ICLR), 2023 </br>
      <a href="https://arxiv.org/abs/2202.05411" target="_blank"> [arxiv] </a> 
    </font>
    </p>
  
    <p>
      <font size="3"> <b>Closed-Loop Data Transcription to an LDR via Minimaxing Rate Reduction</b>  </font></br>
      <font size="3"> Xili Dai*, Shengbang Tong*, Mingyang Li*, <b> Ziyang Wu* </b>, Kwan Ho Ryan Chan, Pengyuan Zhai, Yaodong Yu, Michael Psenka, Xiaojun Yuan, Heung-Yeung Shum, Yi Ma </br>
        MDPI Entropy, 2022 </br>
      <a href="https://www.mdpi.com/1099-4300/24/4/456" target="_blank"> [link] </a> <a href="https://arxiv.org/abs/2111.06636" target="_blank"> [arxiv] </a> 
    </font>
    </p>

    <p>
      <font size="3"> <b>Efficient Maximal Coding Rate Reduction by Variational Forms</b>  </font></br>
      <font size="3"> Christina Baek*, <b> Ziyang Wu*</b>, Kwan Ho Ryan Chan, Tianjiao Ding, Yi Ma, Benjamin Haeffele </br>
        Conference of Computer Vision and Pattern Recognition (CVPR), 2022 </br>
      <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Efficient_Maximal_Coding_Rate_Reduction_by_Variational_Forms_CVPR_2022_paper.pdf" target="_blank"> [link] </a> 
    </font>
    </p>

  <p>
    <font size="3"> <b>How Low Can We Go: Trading Memory for Error in Low-Precision Training</b>  </font></br>
    <font size="3"> Chengrun Yang*, <b> Ziyang Wu* </b>, Jerry Chee, Christopher De Sa, Madeleine Udell </br>
      International Conference on Learning Representations (ICLR), 2022 </br>
      <a href="https://openreview.net/forum?id=YpSxqy_RE84" target="_blank"> [link] </a> <a href="https://arxiv.org/abs/2106.09686" target="_blank"> [arxiv] </a> <a href="https://github.com/chengrunyang/peppp" target="_blank"> [code] </a>
  </font>
  </p>

  <p>
  <font size="3"> <b>Incremental Learning via Rate Reduction</b>  </font></br>
  <font size="3"> <b> Ziyang Wu* </b>, Christina Baek*, Chong You, Yi Ma  </br>
    Conference of Computer Vision and Pattern Recognition (CVPR), 2021 </br>
    ICML Workshop on Theory and Foundation of Continual Learning, 2021 (<b>Oral Presentation</b>)</br>
    <a href="https://arxiv.org/abs/2011.14593" target="_blank"> [arxiv] </a>
  </font>
  </p>

  <p>
  <font size="3"> <b>Can We Characterize Tasks Without Labels or Features</b>   </font></br>
  <font size="3"> Bram Wallace*, <b> Ziyang Wu* </b>, Bharath Hariharan </br>
    Conference of Computer Vision and Pattern Recognition (CVPR), 2021 </br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wallace_Can_We_Characterize_Tasks_Without_Labels_or_Features_CVPR_2021_paper.pdf" target="_blank"> [link] </a> <a href="https://github.com/BramSW/task_characterization_cvpr_2021" target="_blank"> [code] </a>
  </font>
  </p>

  <p>
  <font size="3"> <b> TenIPS: Inverse Propensity Sampling for Tensor Completion</b> </font></br>
  <font size="3"> Chengrun Yang, Lijun Ding, <b> Ziyang Wu </b>, Madeleine Udell </br>
    NeurIPS 2020 Workshop on Optimization for Machine Learning (OPT), 2020 (<b>Oral Presentation</b>)</br>
    International Conference on Artificial Intelligence and Statistics (AISTATS), 2021 </br>
    <a href="https://arxiv.org/abs/2101.00323" target="_blank"> [arxiv] </a> 
  </font>
  </p>


  <p>
  <font size="3"> <b>AutoML Pipeline Selection: Efficiently Navigating the Combinatorial Space</b>  </font></br>
  <font size="3"> Chengrun Yang, Jicong Fan, <b> Ziyang Wu </b>, Madeleine Udell </br>
    ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2020 </br>
    <a href="https://dl.acm.org/doi/abs/10.1145/3394486.3403197" target="_blank"> [link] </a> <a href="https://github.com/udellgroup/oboe" target="_blank"> [code] </a>
  </font>
  </p>

  <!-- <h5> <b> Thesis </b> <font size="3"></font></h5>
    <p>
    <font size="3"> Automated Machine Learning and Task Space Navigation </font></br>
    <font size="3"> <b> Ziyang Wu </b> </br>
      Master’s Thesis, Cornell University, 2021 </br>
      <a href="https://ecommons.cornell.edu/bitstream/handle/1813/109695/Wu_cornell_0058O_11200.pdf?sequence=1" target="_blank"> [link] </a> 
    </font>
    </p> -->
  
  <hr>
    <h4> <b> Talks </b> <font size="3"></font></h4>
    <p>
      <font size="3"> Maximizing Rate Reduction: Principle and Applications </font></br>
      <font size="3"> International Digital Economy Academy (IDEA), Oct. 2021 </br>
      </font>
      </p>
    
      <p>
        <font size="3"> Incremental Learning via Rate Reduction </font></br>
        <font size="3"> ICML Workshop on Theory and Foundation of Continual Learning, Jul. 2021 </br>
          <a href="https://icml.cc/virtual/2021/workshop/8348#wse-detail-13155" target="_blank"> [link] </a> 
        </font>
      </p>
  <hr>
    <h4> <b> Teaching </b> <font size="3"></font></h4>
    <p> CS 4700 (Fall 2018, Fall 2019, Fall 2020): Foundations of Artificial Intelligence (Teaching Assistant) </p>
    <p> CS 2800 (Fall 2016, Spring 2021): Discrete Structures (Teaching Assistant) </p>
    <p> CS 4670/5670 (Spring 2020): Introduction to Computer Vision (Teaching Assistant) </p>
    <p> CS 4820 (Fall 2017, Summer 2020): Introduction to Algorithms (Teaching Assistant) </p>
    <p> CS 3110 (Spring 2017): Data Structures and Functional Programming (Teaching Assistant) </p>


  <hr>
    <h4> <b> Acknowledgement </b> <font size="3"></font></h4>
    <p> Thanks <a href="https://people.eecs.berkeley.edu/~hqi/" target="_blank"> Haozhi Qi </a> for sharing this html template. </p>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="res/js/bootstrap.min.js"></script>
  
  </div>
  </body>
</html>

